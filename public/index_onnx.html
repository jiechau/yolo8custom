<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8n ONNX Inference</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</head>
<body>
    <input type="text" id="imageUrl" value="https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/bus.jpg">
    <button onclick="runInference()" id="submitBtn" disabled>Submit</button>
    <br>
    <canvas id="outputCanvas"></canvas>

    <script>
        const classNames = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'];
        //const classNames = ['Female', 'Male'];

        let session;

        async function loadModel() {
            console.log("Loading ONNX model...");
            // Set numThreads to 1 to avoid the warning
            const options = { executionProviders: ['wasm'], wasm: { numThreads: 1 } };
            session = await ort.InferenceSession.create('yolov8n.onnx', options);
            //session = await ort.InferenceSession.create('best.onnx', options);
            console.log("ONNX model loaded successfully");
        }

        async function runInference() {
            console.log("Starting inference...");
            const imageUrl = document.getElementById('imageUrl').value;
            console.log("Image URL:", imageUrl);

            try {
                const img = await loadImageFromUrl(imageUrl);
                console.log("Image loaded, dimensions:", img.width, "x", img.height);

                const tensor = imageToTensor(img);
                console.log("Image converted to tensor, shape:", tensor.dims);

                const feeds = { images: tensor };
                console.log("Running ONNX inference...");
                const results = await session.run(feeds);
                console.log("Inference complete, results:", results);

                const canvas = document.getElementById('outputCanvas');
                canvas.width = img.width;
                canvas.height = img.height;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(img, 0, 0);

                drawDetections(results.output0.data, img.width, img.height, ctx);
                console.log("Detections drawn on canvas");
            } catch (error) {
                console.error("Error during inference:", error);
            }
        }

        async function loadImageFromUrl(url) {
            console.log("Loading image from URL:", url);
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.crossOrigin = "Anonymous";
                img.onload = () => {
                    console.log("Image loaded successfully");
                    resolve(img);
                };
                img.onerror = (error) => {
                    console.error("Error loading image:", error);
                    reject(error);
                };
                img.src = url;
            });
        }

        function imageToTensor(img) {
            console.log("Converting image to tensor...");
            const canvas = document.createElement('canvas');
            canvas.width = 640;
            canvas.height = 640;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(img, 0, 0, 640, 640);
            const imageData = ctx.getImageData(0, 0, 640, 640);
            const { data } = imageData;
            const redArray = new Float32Array(640 * 640);
            const greenArray = new Float32Array(640 * 640);
            const blueArray = new Float32Array(640 * 640);
            
            for (let i = 0, j = 0; i < data.length; i += 4, j++) {
                redArray[j] = data[i] / 255.0;
                greenArray[j] = data[i + 1] / 255.0;
                blueArray[j] = data[i + 2] / 255.0;
            }
            
            const tensorData = new Float32Array(3 * 640 * 640);
            tensorData.set(redArray, 0);
            tensorData.set(greenArray, 640 * 640);
            tensorData.set(blueArray, 2 * 640 * 640);
            
            console.log("Image converted to tensor successfully");
            return new ort.Tensor('float32', tensorData, [1, 3, 640, 640]);
        }

        function drawDetections(outputData, imgWidth, imgHeight, ctx) {
            console.log("Drawing detections...");
            const threshold = 0.5;
            const boxes = [];
            const scores = [];
            const classes = [];

            const numClasses = classNames.length;
            const numBoxes = outputData.length / (numClasses + 5);

            for (let i = 0; i < numBoxes; i++) {
                const baseIndex = i * (numClasses + 5);
                const [x, y, w, h, conf] = outputData.slice(baseIndex, baseIndex + 5);
                const classScores = outputData.slice(baseIndex + 5, baseIndex + 5 + numClasses);
                const classIndex = classScores.indexOf(Math.max(...classScores));

                if (conf > threshold) {
                    boxes.push([x - w/2, y - h/2, w, h]);
                    scores.push(conf);
                    classes.push(classIndex);
                }
            }

            console.log(`Found ${boxes.length} detections above threshold`);

            for (let i = 0; i < boxes.length; i++) {
                const [x, y, w, h] = boxes[i];
                const label = classNames[classes[i]];
                const score = scores[i];
                const color = `hsl(${classes[i] * 137.5 % 360}, 70%, 50%)`;

                ctx.strokeStyle = color;
                ctx.lineWidth = 2;
                ctx.strokeRect(
                    x * imgWidth, y * imgHeight,
                    w * imgWidth, h * imgHeight
                );

                ctx.fillStyle = color;
                ctx.font = '12px Arial';
                ctx.fillText(
                    `${label} ${score.toFixed(2)}`,
                    x * imgWidth, y * imgHeight - 5
                );

                console.log(`Detection ${i + 1}: ${label} (${score.toFixed(2)}) at [${x.toFixed(2)}, ${y.toFixed(2)}, ${w.toFixed(2)}, ${h.toFixed(2)}]`);
            }
        }

        function onOpenCvReady() {
            document.getElementById('submitBtn').disabled = false;
            console.log('OpenCV.js is ready');
            loadModel();
        }
    </script>
</body>
</html>
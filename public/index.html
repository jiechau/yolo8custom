<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>YOLOv8n ONNX Inference with Webcam</title>
    <style>
        body { text-align: center; }
        video, canvas { margin: 20px auto; display: block; }
        #results { font-size: 20px; }
    </style>
</head>
<body>
    <h1>YOLOv8n ONNX Inference with Webcam</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    <div id="results"></div>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const resultsDiv = document.getElementById('results');
        let session;

        async function setupWebcam() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => { resolve(video); };
            });
        }

        async function loadModel() {
            session = await ort.InferenceSession.create('./best.onnx', {
                executionProviders: ['wasm'],
                wasm: { numThreads: 2 }
            });
        }

        function preprocessImage(imageData) {
            const { data, width, height } = imageData;
            const float32Data = new Float32Array(width * height * 3);
            for (let i = 0; i < width * height; i++) {
                float32Data[i * 3 + 0] = data[i * 4 + 0] / 255.0; // R
                float32Data[i * 3 + 1] = data[i * 4 + 1] / 255.0; // G
                float32Data[i * 3 + 2] = data[i * 4 + 2] / 255.0; // B
            }
            return float32Data;
        }

        async function runInference() {
            if (video.readyState !== video.HAVE_ENOUGH_DATA) {
                requestAnimationFrame(runInference);
                return;
            }

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const float32Data = preprocessImage(imageData);
            const input = new ort.Tensor('float32', float32Data, [1, 3, canvas.height, canvas.width]);

            const feeds = { input: input };
            const outputData = await session.run(feeds);
            const boxes = outputData.boxes.data;
            const scores = outputData.scores.data;

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            drawBoxes(boxes, scores);

            requestAnimationFrame(runInference);
        }

        function drawBoxes(boxes, scores) {
            ctx.strokeStyle = 'red';
            ctx.lineWidth = 2;
            for (let i = 0; i < boxes.length; i += 4) {
                const score = scores[i / 4];
                if (score > 0.5) {
                    const [x1, y1, x2, y2] = boxes.slice(i, i + 4);
                    ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
                }
            }
        }

        async function main() {
            await setupWebcam();
            await loadModel();
            runInference();
        }

        main();
    </script>
</body>
</html>

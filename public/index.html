<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8 Object Detection with Webcam</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.14.0/ort.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; }
        #videoElement { width: 100%; max-width: 640px; height: auto; }
        #canvasElement { position: absolute; top: 0; left: 0; z-index: 1; }
        #infoFrame, #inputContainer, #outputArea { margin: 10px 0; }
        #fpsInput { width: 50px; }
    </style>
</head>
<body>
    <div id="infoFrame">
        <h1>YOLOv8 Object Detection with Webcam</h1>
        <div id="inputContainer">
            <label for="fpsInput">Set FPS:</label>
            <input type="number" id="fpsInput" value="30" min="1" max="60">
            <button id="startButton">Start Detection</button>
        </div>
    </div>

    <div style="position: relative;">
        <video id="videoElement" autoplay playsinline></video>
        <canvas id="canvasElement"></canvas>
    </div>

    <div id="outputArea"></div>

    <script>
        const video = document.getElementById('videoElement');
        const canvas = document.getElementById('canvasElement');
        const ctx = canvas.getContext('2d');
        const fpsInput = document.getElementById('fpsInput');
        const startButton = document.getElementById('startButton');
        const outputArea = document.getElementById('outputArea');
        let model;
        let isRunning = false;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    resolve(video);
                };
            });
        }

        async function loadModel() {
            try {
                // Replace with the actual path to your ONNX model
                model = await ort.InferenceSession.create('yolov8n.onnx');
                console.log('ONNX model loaded successfully');
            } catch (error) {
                console.error('Failed to load ONNX model:', error);
                outputArea.textContent = 'Failed to load ONNX model: ' + error.message;
            }
        }

        async function runInference() {
            if (!model) return;

            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const tensor = new ort.Tensor('uint8', imageData.data, [1, canvas.height, canvas.width, 4]);

            try {
                const results = await model.run({ images: tensor });
                drawBoundingBoxes(results);
            } catch (error) {
                console.error('Inference failed:', error);
                outputArea.textContent = 'Inference failed: ' + error.message;
            }
        }

        function drawBoundingBoxes(results) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Assuming the model output is in YOLO format
            // You'll need to adjust this based on your specific model output
            const boxes = results.output0.data;
            const numBoxes = boxes.length / 7; // Assuming each box has 7 values

            for (let i = 0; i < numBoxes; i++) {
                const [x1, y1, x2, y2, score, classId] = boxes.slice(i * 7, (i + 1) * 7);
                
                if (score > 0.5) {  // Confidence threshold
                    ctx.strokeStyle = 'red';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

                    ctx.fillStyle = 'red';
                    ctx.font = '16px Arial';
                    ctx.fillText(`Class ${classId} (${score.toFixed(2)})`, x1, y1 - 5);
                }
            }
        }

        async function processFrame() {
            if (isRunning) {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                await runInference();
                setTimeout(processFrame, 1000 / parseInt(fpsInput.value));
            }
        }

        startButton.addEventListener('click', async () => {
            if (!isRunning) {
                isRunning = true;
                startButton.textContent = 'Stop Detection';
                await setupCamera();
                await loadModel();
                processFrame();
            } else {
                isRunning = false;
                startButton.textContent = 'Start Detection';
            }
        });

    </script>
</body>
</html>